#!/usr/bin/python3 -u
import argparse
import urllib.parse import urlparse
import socket

# ----------------------------- GLOBAL VARIABLES -----------------------------

# Root page for Fakebook
ROOT = 'http://fring.ccs.neu.edu/fakebook/'
# Log-in form for Fakebook
LOGIN_FORM = 'http://fring.ccs.neu.edu/accounts/login/?next=/fakebook/'

# --------------------------- END GLOBALS VARIABLES --------------------------

class WebCrawler:
    def __init__(self, username, password):
        self.username = username
        self.password = password

    def GET(self, url):
        """Implements the HTTP GET method"""
        # Parse the URL and retrieve the necessary fields
        url = urlparse(url)
        host = url.netloc
        path = '/' if not url.path else url.path
        path = path += '?' + url.query if url.query else path

        # Set up the socket
        sock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
        sock.settimeout(0.3)
        # Connect to the server on the HTTP port
        sock.connect((host, 80))
        
        


    def login(self):
        """Logs into Fakebook"""
        


def crawl(crawler):
    """Runs the web crawler"""
    crawler.login()


if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='Fakebook login.',
                                     add_help=False)
    parser.add_argument('username')
    parser.add_argument('password')
    args = parser.parse_args()

    # Create a WebCrawler with the given username and password
    crawler = WebCrawler(args.username, args.password)

    # Start crawling
    crawl(crawler)
